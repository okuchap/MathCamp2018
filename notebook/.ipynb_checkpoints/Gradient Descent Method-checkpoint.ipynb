{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Method\n",
    "\n",
    "## Idea behind the algorithm\n",
    "\n",
    "* Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function.\n",
    "\n",
    "* The algorithm is based on Taylor expansion:\n",
    "\n",
    "* Suppose $f:\\mathbb{R^n} \\to \\mathbb{R}$, $x, d \\in \\mathbb{R^n}$ and $t \\in \\mathbb{R_+}$.\n",
    "\n",
    "$$f(\\bar{x} + td) = f(\\bar{x}) + t [Df(\\bar{x})]^\\top d + O(t^2)$$\n",
    "\n",
    "* If we take $d := - Df(\\bar{x})$ and take $t$ that is small enough,\n",
    "    \n",
    "$$f(\\bar{x} - t Df(\\bar{x})) \\approx f(\\bar{x}) - t \\|Df(\\bar{x})\\|^2 < f(\\bar{x})$$\n",
    "\n",
    "* From these observations, one might come up with the following algorithm:\n",
    "    0. Set an initial point $x_0$.\n",
    "    1. $k \\leftarrow 0$\n",
    "    2. Set some small $t$.\n",
    "    3. Calculate $x_{k+1} := x_{k} - t \\cdot Df(x_k)$\n",
    "    4. If $x_{k+1}$ does not satisfy some halting condition, $k \\leftarrow k + 1$ and go back to Step 4.\n",
    "    5. Return $x^* = x_{k+1}$ as the numerical solution.\n",
    "\n",
    "## Example:\n",
    "\n",
    "* Let's obtain the minimum of the following function:\n",
    "\n",
    "$$f(x) := x^4 âˆ’ 3 x^3 + 2$$\n",
    "\n",
    "* We know $f$'s minimizer is $x^* := 9/4 = 2.25$.\n",
    "\n",
    "* Let's see if gradient descent method offers this solution.\n",
    "\n",
    "* Also see how the algotithm behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T03:37:47.436960Z",
     "start_time": "2018-02-25T03:37:47.427523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local minimum: 2.249965\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "## The algorithm certainly offers the minimizer.\n",
    "\n",
    "current_x = 6 # The algorithm starts at x=6\n",
    "t = 0.01 # step size multiplier\n",
    "precision = 0.00001\n",
    "previous_step_size = float('inf')\n",
    "\n",
    "df = lambda x: 4 * x**3 - 9 * x**2\n",
    "\n",
    "while previous_step_size > precision:\n",
    "    previous_x = current_x\n",
    "    current_x += - t * df(previous_x)\n",
    "    previous_step_size = abs(current_x - previous_x)\n",
    "\n",
    "print(\"The local minimum: %f\" % current_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T03:45:22.923197Z",
     "start_time": "2018-02-25T03:45:22.908613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1, Current x: 0.6000\n",
      "Iteration:  5, Current x: 0.7048\n",
      "Iteration: 10, Current x: 0.8805\n",
      "Iteration: 15, Current x: 1.1211\n",
      "Iteration: 20, Current x: 1.4294\n",
      "Iteration: 25, Current x: 1.7607\n",
      "Iteration: 30, Current x: 2.0208\n",
      "Iteration: 35, Current x: 2.1620\n",
      "Iteration: 40, Current x: 2.2196\n",
      "Iteration: 45, Current x: 2.2400\n",
      "Iteration: 50, Current x: 2.2467\n",
      "Iteration: 55, Current x: 2.2489\n",
      "Iteration: 60, Current x: 2.2497\n",
      "Iteration: 65, Current x: 2.2499\n",
      "Iteration: 70, Current x: 2.2500\n",
      "The total number of iterations: 71\n",
      "The local minimum: 2.249965\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "## The behavior of the algorithm\n",
    "\n",
    "current_x = 6 # The algorithm starts at x=6\n",
    "t = 0.01 # step size multiplier\n",
    "precision = 0.00001\n",
    "previous_step_size = float('inf')\n",
    "\n",
    "df = lambda x: 4 * x**3 - 9 * x**2\n",
    "iteration = 1\n",
    "\n",
    "while previous_step_size > precision:\n",
    "    previous_x = current_x\n",
    "    current_x += - t * df(previous_x)\n",
    "    previous_step_size = abs(current_x - previous_x)\n",
    "    if (iteration % 5 == 0 or iteration == 1):\n",
    "        print(\"Iteration: {0:>2}, Current x: {1:.4f}\".format(iteration, current_x))\n",
    "    iteration += 1\n",
    "\n",
    "print(\"The total number of iterations: {}\".format(iteration))\n",
    "print(\"The local minimum: %f\" % current_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T03:45:09.627984Z",
     "start_time": "2018-02-25T03:45:09.612367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial point: -2, The local minimum: -0.0105\n",
      "Initial point: -1, The local minimum: -0.0105\n",
      "Initial point:  0, The local minimum: 0.0000\n",
      "Initial point:  1, The local minimum: 2.2500\n",
      "Initial point:  2, The local minimum: 2.2500\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "## Different initial points converge to different local minima.\n",
    "\n",
    "def gd(init):\n",
    "    current_x = init # The algorithm starts at x=6\n",
    "    t = 0.01 # step size multiplier\n",
    "    precision = 0.00001\n",
    "    previous_step_size = float('inf')\n",
    "\n",
    "    df = lambda x: 4 * x**3 - 9 * x**2\n",
    "\n",
    "    while previous_step_size > precision:\n",
    "        previous_x = current_x\n",
    "        current_x += - t * df(previous_x)\n",
    "        previous_step_size = abs(current_x - previous_x)\n",
    "\n",
    "    print('Initial point: {0:>2}, The local minimum: {1:.4f}'.format(init, current_x))\n",
    "\n",
    "for init in [-2, -1, 0, 1, 2]:\n",
    "    gd(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T03:43:50.886422Z",
     "start_time": "2018-02-25T03:43:50.873659Z"
    }
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-62b425ccf11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Some initial points may result in error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-423db023062b>\u001b[0m in \u001b[0;36mgd\u001b[0;34m(init)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mprevious_step_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprevious_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcurrent_x\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprevious_step_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprevious_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-423db023062b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprevious_step_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mprevious_step_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "## Some initial points may result in error:\n",
    "gd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
